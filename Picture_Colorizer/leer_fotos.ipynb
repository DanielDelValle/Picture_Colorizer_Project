{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from cv2 import imread, imwrite\n",
    "import os\n",
    "import glob\n",
    "from tensorflow.image import psnr as psnr\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import savefig\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from numpy import reshape\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior()"
   ]
  },
  {
   "source": [
    "path_airplane = 'natural_images\\\\airplane\\\\*.jpg'\n",
    "path_car = 'natural_images\\\\car\\\\*.jpg'\n",
    "path_cat = 'natural_images\\\\cat\\\\*.jpg'\n",
    "path_dog = 'natural_images\\\\dog\\\\*.jpg'\n",
    "path_flower = 'natural_images\\\\flower\\\\*.jpg'\n",
    "path_fruit = 'natural_images\\\\fruit\\\\*.jpg'\n",
    "path_motorbike = 'natural_images\\\\motorbike\\\\*.jpg'\n",
    "path_person = 'natural_images\\\\person\\\\*.jpg'\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "paths_list = [path_airplane, path_car, path_cat, path_dog, path_flower, path_fruit,  path_motorbike, path_person]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_list2 = [path_flower]"
   ]
  },
  {
   "source": [
    "acum = 1\n",
    "for path in paths_list:\n",
    "    filenames = glob.glob(path)\n",
    "    for filename in filenames:\n",
    "        image = cv2.imread(filename)\n",
    "        gray_img = cv2.imread(filename, 0)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        gray_img = cv2.resize(gray_img, (128, 128))\n",
    "        cv2.imwrite(\"gray128/gray_\" +str(acum) +\".jpg\", gray_img)\n",
    "        cv2.imwrite(\"color128/color_\" +str(acum) +\".jpg\", image)\n",
    "        acum += 1"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "acum = 1\n",
    "for path in paths_list:\n",
    "    filenames = glob.glob(path)\n",
    "    for filename in filenames:\n",
    "        image = cv2.imread(filename)\n",
    "        gray_img = cv2.imread(filename, 0)\n",
    "        image = cv2.resize(image, (256, 256))\n",
    "        gray_img = cv2.resize(gray_img, (256, 256))\n",
    "        cv2.imwrite(\"gray256/gray_\" +str(acum) +\".jpg\", gray_img)\n",
    "        cv2.imwrite(\"color256/color_\" +str(acum) +\".jpg\", image)\n",
    "        acum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acum = 1\n",
    "for path in paths_list2:\n",
    "    filenames = glob.glob(path)\n",
    "    for filename in filenames:\n",
    "        image = cv2.imread(filename)\n",
    "        gray_img = cv2.imread(filename, 0)\n",
    "        image = cv2.resize(image, (256, 256))\n",
    "        gray_img = cv2.resize(gray_img, (256, 256))\n",
    "        cv2.imwrite(\"grayReduced/gray_\" +str(acum) +\".jpg\", gray_img)\n",
    "        cv2.imwrite(\"colorReduced/color_\" +str(acum) +\".jpg\", image)\n",
    "        acum += 1"
   ]
  },
  {
   "source": [
    "num_images = 1843\n",
    "\n",
    "dataset = []\n",
    "\n",
    "#Read all grayscale images and append into numpy list\n",
    "for i in range(1, num_images+1):\n",
    "    img = cv2.imread(\"gray_images/gray_\" +str(i) +\".jpg\", 0)\n",
    "    dataset.append(np.array(img))\n",
    "\n",
    "dataset_source = np.asarray(dataset)\n",
    "print(dataset_source.shape)\n",
    "\n",
    "dataset_tar = []\n",
    "\n",
    "#Read all color images and append into numpy list\n",
    "for i in range(1, num_images+1):\n",
    "    img = cv2.imread(\"color_images/color_\" +str(i) +\".jpg\")    \n",
    "    dataset_tar.append(np.array(img))\n",
    "\n",
    "dataset_target = np.asarray(dataset_tar)\n",
    "print(dataset_target.shape) "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_source = dataset_source.reshape(2, 128, 128, 1)\n",
    "dataset_target = dataset_target.reshape(2, 128, 128, 3)\n",
    "print(dataset_source.shape, dataset_target.shape)\n",
    "type(dataset_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_source = np.array(dataset_source)/255.0\n",
    "\n",
    "dataset_target = np.array(dataset_target)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(128, 128, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder    \n",
    "net1 = Conv2D(1,(2, 2), activation = 'relu', padding='same')(inputs)\n",
    "\n",
    "# Decoder  \n",
    "net2 = Conv2D(3,(2, 2), activation = None,  padding = 'same')(net1)\n",
    "autoencoder = Model(inputs, net2)\n",
    "#loss = tf.reduce_mean(tf.square(dataset_target - dataset_source))\n",
    "autoencoder.compile(optimizer='adam', loss='mae')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(dataset_source[0], dataset_target[0], epochs=3, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = autoencoder.predict(dataset_target)\n",
    "plt.imshow(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs = np.expand_dims(outputs, axis=0)\n",
    "#dataset_source2 = cv2.resize(dataset_target, dsize = (128, 128), interpolation = cv2.INTER_CUBIC)//INTER_NEAREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}